{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "6vHT-HrJ7x0g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "THAlmmGwBpL_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN Models:\n",
        "## CIFAR-10 Dataset\n",
        "### Using tensorflow-gpu and Keras"
      ]
    },
    {
      "metadata": {
        "id": "Brly_qJq7rNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c468a28-7d26-4d8e-eafb-4615ae28674c"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DI_dUH7-0BM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 1:\n",
        "#### 4 convolution layers, 1 dense layer, 50,000 images training set, 10,000 images test set, 8 batches and 25 epochs, Activation functions: ReLU for input & hidden, Softmax for Output layers\n",
        "### Result: Accuracy : 55.14% ; Loss: 1.352"
      ]
    },
    {
      "metadata": {
        "id": "-j3gGx4F7wXw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Conv2D(32, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "model1.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Conv2D(64, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(512))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(num_classes))\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "#summarizes opted model\n",
        "model1.summary()\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model1.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "\n",
        "# Score trained model.\n",
        "scores = model1.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6vHT-HrJ7x0g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 2:\n",
        "#### 4 convolution layers, 1 dense layer, 50,000 images training set, 10,000 images test set, 32 batches and 15 epochs, Activation functions: ReLU for input & hidden, Softmax for Output layers\n",
        "### Result: Accuracy : 68.90% ; Loss: 0.9034"
      ]
    },
    {
      "metadata": {
        "id": "bh-08KUg8FwV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 15\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(32, (3, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(64, (3, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(512))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(num_classes))\n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model2.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model2.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "\n",
        "# Score trained model.\n",
        "scores = model2.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WFvo_PRI8kBH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 3:\n",
        "#### 4 convolution layers, 1 dense layer, 50,000 images training set, 10,000 images test set, 32 batches and 25 epochs, Activation functions: ReLU for input & hidden, Softmax for Output layers\n",
        "### Result: Accuracy : 73.64% ; Loss: 0.7635\n",
        "#### ** Referred from Keras official tutorials"
      ]
    },
    {
      "metadata": {
        "id": "Vjn5OAQ4873V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Conv2D(32, (3, 3)))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Dropout(0.25))\n",
        "\n",
        "model3.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Conv2D(64, (3, 3)))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Dropout(0.25))\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(512))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(num_classes))\n",
        "model3.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model3.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ks1CTVG7BagX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  BatchNormalization used from here onwards & bumped up batches and number of epochs"
      ]
    },
    {
      "metadata": {
        "id": "BoBvzuC7BIHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 4:\n",
        "#### 4 convolution layers, 0 dense layer, 50,000 images training set, 10,000 images test set, 64 batches and 25 epochs, Activation functions: tanh for input & hidden, Softmax for Output layers\n",
        "### Result: Accuracy : 62.38% ; Loss: 1.2244"
      ]
    },
    {
      "metadata": {
        "id": "LC1zcaeVB44y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "weight_decay = 1e-4\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Conv2D(32, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model4.add(Activation('tanh'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model4.add(Activation('tanh'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Dropout(0.3))\n",
        "\n",
        "model4.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model4.add(Activation('tanh'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model4.add(Activation('tanh'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Dropout(0.3))\n",
        "\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model4.summary()\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model4.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model4.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "\n",
        "# Score trained model.\n",
        "scores = model4.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9_9V1LuCR6G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 5:\n",
        "#### 6 convolution layers, 0 dense layer, 50,000 images training set, 10,000 images test set, 64 batches and 25 epochs, Activation functions: elu for input & hidden, Softmax for Output layers\n",
        "### Result: Accuracy : 74.68% ; Loss: 0.8054"
      ]
    },
    {
      "metadata": {
        "id": "vxe4cEN5CcAy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten,BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers\n",
        "import os\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "weight_decay = 1e-4\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model5 = Sequential()\n",
        "model5.add(Conv2D(32, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Dropout(0.3))\n",
        "\n",
        "model5.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Dropout(0.3))\n",
        "\n",
        "model5.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Dropout(0.3))\n",
        "\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model5.summary()\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model5.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model5.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model5.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model5.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SondyBmHxSVl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 6:\n",
        "#### 6 convolution layers, 0 dense layer, 50,000 images training set, 10,000 images test set, 64 batches and 125 epochs, Activation functions: elu for input & hidden, Softmax for Output layers\n",
        "### Result: Accuracy : 86.12% ; Loss: 0.4734"
      ]
    },
    {
      "metadata": {
        "id": "FMDNxXlcxUGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "weight_decay = 1e-4\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model5 = Sequential()\n",
        "model5.add(Conv2D(32, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Dropout(0.3))\n",
        "\n",
        "model5.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Dropout(0.3))\n",
        "\n",
        "model5.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model5.add(Activation('elu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Dropout(0.3))\n",
        "\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model5.summary()\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model5.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model5.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model5.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model5.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bR-0sHuQxmTe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model vs Accuracy:\n",
        "### Contrasting the accuracy and loss with respect to the features of the models"
      ]
    },
    {
      "metadata": {
        "id": "V2f8Dtkyxprk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "34809785-619b-46bd-9951-a926ace200c8"
      },
      "cell_type": "code",
      "source": [
        "x1 = [1,2,3,4,5,6] \n",
        "y1 = [55.14,68.9,73.64,62.38,74.68,86.12] \n",
        "# plotting the line 1 points  \n",
        "plt.plot(x1, y1, label = \"Accuracy\")  \n",
        "# naming the x axis \n",
        "plt.xlabel('Models') \n",
        "# naming the y axis \n",
        "plt.ylabel('Accuracy (0-100)') \n",
        "# giving a title to my graph \n",
        "plt.title('Models vs Accuracy') \n",
        "for a,b in zip(x1, y1): \n",
        "    plt.text(a, b, str(b)+'%')\n",
        "# show a legend on the plot \n",
        "plt.legend() \n",
        "  \n",
        "# function to show the plot \n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAFnCAYAAAA/o5q7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7c33e55320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "s4JniD8Qxtsp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The accuracy drop in Model-4 from increasing 73.64% to 62.38% is majorly because of using 'tanh' activation function for all the hidden layers and also because of less number of convolution layers."
      ]
    }
  ]
}